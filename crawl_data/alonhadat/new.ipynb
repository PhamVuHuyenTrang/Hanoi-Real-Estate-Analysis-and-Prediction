{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting undetected_chromedriver\n",
      "  Downloading undetected-chromedriver-3.1.7.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 686 kB/s \n",
      "\u001b[?25hRequirement already satisfied: selenium>=4.0.0 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from undetected_chromedriver) (4.1.0)\n",
      "Requirement already satisfied: requests in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from undetected_chromedriver) (2.25.1)\n",
      "Collecting websockets\n",
      "  Downloading websockets-10.4-cp38-cp38-macosx_10_9_x86_64.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: trio-websocket~=0.9 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from selenium>=4.0.0->undetected_chromedriver) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from selenium>=4.0.0->undetected_chromedriver) (0.19.0)\n",
      "Requirement already satisfied: urllib3[secure]~=1.26 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from selenium>=4.0.0->undetected_chromedriver) (1.26.4)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium>=4.0.0->undetected_chromedriver) (1.10)\n",
      "Requirement already satisfied: sniffio in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium>=4.0.0->undetected_chromedriver) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium>=4.0.0->undetected_chromedriver) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium>=4.0.0->undetected_chromedriver) (20.3.0)\n",
      "Requirement already satisfied: idna in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium>=4.0.0->undetected_chromedriver) (2.10)\n",
      "Requirement already satisfied: outcome in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio~=0.17->selenium>=4.0.0->undetected_chromedriver) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium>=4.0.0->undetected_chromedriver) (1.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium>=4.0.0->undetected_chromedriver) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium>=4.0.0->undetected_chromedriver) (20.0.1)\n",
      "Requirement already satisfied: certifi in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from urllib3[secure]~=1.26->selenium>=4.0.0->undetected_chromedriver) (2022.6.15)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium>=4.0.0->undetected_chromedriver) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium>=4.0.0->undetected_chromedriver) (2.20)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium>=4.0.0->undetected_chromedriver) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.0.0->undetected_chromedriver) (0.12.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/tranxuanhuy/opt/anaconda3/lib/python3.8/site-packages (from requests->undetected_chromedriver) (4.0.0)\n",
      "Building wheels for collected packages: undetected-chromedriver\n",
      "  Building wheel for undetected-chromedriver (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.1.7-py3-none-any.whl size=45412 sha256=a73ec35ad87d4446d02922d88a5f7562a664e59182d0aeac576be29fd335939d\n",
      "  Stored in directory: /Users/tranxuanhuy/Library/Caches/pip/wheels/5f/35/f2/a6f20630c5c90a565e082ab1eea19a7a6696fa09f66c7aab01\n",
      "Successfully built undetected-chromedriver\n",
      "Installing collected packages: websockets, undetected-chromedriver\n",
      "Successfully installed undetected-chromedriver-3.1.7 websockets-10.4\n"
     ]
    }
   ],
   "source": [
    "!pip install undetected_chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from  lxml import etree\n",
    "import json \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import undetected_chromedriver as uc\n",
    "import traceback\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5,5 tỷ \n"
     ]
    }
   ],
   "source": [
    "service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "url = \"https://alonhadat.com.vn/ban-nha-dep-quan-hai-ba-trung-50m-5-tang-5-5-ty-12173405.html\"\n",
    "driver.get(url)\n",
    "bs = BeautifulSoup(driver.page_source)\n",
    "\n",
    "page = etree.HTML(str(bs))\n",
    "price = page.xpath(\"\"\"//*[@id=\"left\"]/div[1]/div[3]/span[1]/span[2]\"\"\")[0].text\n",
    "print(price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME=0.5\n",
    "\n",
    "class crawling:\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.home_page = \"https://alonhadat.com.vn/nha-dat/can-ban/nha-dat/1/ha-noi.html\"\n",
    "        self.root = \"https://alonhadat.com.vn\"\n",
    "        self.page = 1\n",
    "\n",
    "    \n",
    "    def get_pages(self, page_source):\n",
    "        bs = BeautifulSoup(page_source)\n",
    "        page = etree.HTML(str(bs))\n",
    "\n",
    "        elements = bs.find_all(\"div\", {\"class\": \"ct_title\"})\n",
    "        data = []\n",
    "        try:\n",
    "            for feature in elements:\n",
    "                feature = feature.find_all('a', href=True)\n",
    "                data.append(feature[0]['href'])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return [self.root+link for link in data]\n",
    "    \n",
    "    def next_page(self):\n",
    "        self.page += 1\n",
    "        return self.home_page[:-5] + f\"/trang--{self.page}.html\"\n",
    "        # return  self.home_page + \"f/p{self.page}\"\n",
    "\n",
    "    def get_id(self, page_source):\n",
    "        bs = BeautifulSoup(page_source)\n",
    "        page = etree.HTML(str(bs))\n",
    "        address = page.xpath(\"\"\"//*[@id=\"left\"]/div[1]/div[5]/div[2]/table/tbody/tr[1]\"\"\")[0]\n",
    "        print(address)\n",
    "        return address.getchildren()[1].text\n",
    "    \n",
    "    def gather(self, page_source):\n",
    "        data = {}\n",
    "        bs = BeautifulSoup(page_source)\n",
    "        page = etree.HTML(str(bs))\n",
    "        \n",
    "        # get price\n",
    "        # price = bs.find_all('span', {'class': 'price'})\n",
    "        price = page.xpath(\"\"\"//*[@id=\"left\"]/div[1]/div[3]/span[1]/span[2]\"\"\")[0].text\n",
    "        price = price.replace(\",\", \".\")\n",
    "        data['price'] = price\n",
    "\n",
    "        # get area\n",
    "        area = page.xpath(\"\"\"//*[@id=\"left\"]/div[1]/div[3]/span[2]/span[2]\"\"\")[0].text\n",
    "        data['area'] = area\n",
    "        \n",
    "        # get address\n",
    "        address = page.xpath(\"\"\"//*[@id=\"left\"]/div[1]/div[4]/span[2]\"\"\")[0].text\n",
    "        address = address.replace(\",\", \".\")\n",
    "        data['address'] = address\n",
    "\n",
    "        # get table information\n",
    "        table = bs.find_all('div', {'class': 'infor'})[0]\n",
    "        tr_instances = table.find_all('tr')\n",
    "        for i in range(len(tr_instances)):\n",
    "            td_instances = tr_instances[i].find_all('td')\n",
    "            for j in range(3):\n",
    "                data[str(td_instances[2*j].text).strip()] = str(td_instances[2*j+1].text)\n",
    "        return data\n",
    "\n",
    "    def run(self, start, num_of_pages):\n",
    "        service = ChromeService(executable_path=ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        url = self.home_page\n",
    "        self.page = 1\n",
    "        if start != 1:\n",
    "            self.page = start\n",
    "            url = self.home_page[:-5] + f\"/trang--{self.page}.html\"\n",
    "        if os.path.exists(\"data/index.json\"):\n",
    "            with open(\"data/index.json\") as f:\n",
    "                index = set(json.load(f))\n",
    "        else:\n",
    "            index = set()\n",
    "            \n",
    "        with open(\"log.txt\", \"w\") as f:\n",
    "            pass\n",
    "        \n",
    "        dataset = []\n",
    "        for i in range(num_of_pages):\n",
    "            num = 10\n",
    "            pages = []\n",
    "            while num > 0:\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    time.sleep(TIME)\n",
    "                    pages = self.get_pages(driver.page_source)\n",
    "                    driver.delete_all_cookies()\n",
    "                    break\n",
    "                except:\n",
    "                    num -= 1\n",
    "            if num <= 0:\n",
    "                url = self.next_page()\n",
    "                continue\n",
    "\n",
    "            for page in tqdm(pages):\n",
    "                num = 1\n",
    "                while num > 0:\n",
    "                    try:\n",
    "                        driver.get(page)\n",
    "                        time.sleep(TIME)\n",
    "                        id = self.get_id(driver.page_source)\n",
    "                        if id in index: \n",
    "                            print(id, \"exist\")\n",
    "                            break\n",
    "\n",
    "                        data = self.gather(driver.page_source)\n",
    "                        \n",
    "                        if data[\"Mã tin\"] not in index:\n",
    "                            dataset.append(data)\n",
    "                            index.add(data[\"Mã tin\"])\n",
    "                        with open(\"log.txt\", \"a\") as f:\n",
    "                            f.write(\"Success:\" + page +\"\\n\")\n",
    "                        driver.delete_all_cookies()\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(e, \"unknown\")\n",
    "                        with open(\"log.txt\", \"a\") as f:\n",
    "                            f.write(f\"Excution{5-num}: {page}\"+\"\\n\") \n",
    "                            f.write(traceback.format_exc()+\"\\n\")\n",
    "                        \n",
    "                        with open(\"failed.txt\", \"a\") as f:\n",
    "                            f.write(f\"Excution{5-num}: {page}\"+\"\\n\") \n",
    "                            f.write(traceback.format_exc()+\"\\n\")\n",
    "                        driver.delete_all_cookies()\n",
    "                        num -= 1\n",
    "            url = self.next_page()\n",
    "        if len(dataset) != 0:\n",
    "            df = pd.DataFrame(dataset)\n",
    "            df.to_csv(f\"data/{start}_{start+num_of_pages}_{time.time()}.csv\", index=False)\n",
    "        with open(\"data/index.json\", \"w\") as f:\n",
    "            json.dump(list(index), f)\n",
    "        driver.close()\n",
    "        \n",
    "craw = crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cần bán: 11353 (the last page)\n",
    "# Cho thuê: 1211 (the last page)\n",
    "\n",
    "for i in range(1, 3):\n",
    "    craw.run(i, 1)\n",
    "    clear_output()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5149034e6c270e282a77d1814557afd12f20860eafa66ad63ec09ade6ca502a7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
