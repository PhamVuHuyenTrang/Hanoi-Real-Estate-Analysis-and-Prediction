{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from  lxml import etree\n",
    "import json \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import undetected_chromedriver as uc\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CĐT - bán chung cư Văn Miếu - Nguyễn Thái Học gần Hoàn Kiếm\n"
     ]
    }
   ],
   "source": [
    "service = webdriver.edge.service.Service(\"edgedriver_win64\\msedgedriver.exe\")\n",
    "driver = webdriver.Edge(service=service)\n",
    "url = \"https://homedy.com/ban-can-ho-quan-dong-da-ha-noi/cdt-chung-cu-van-mieu-nguyen-thai-hoc-gan-hoan-kiem-es1882888\"\n",
    "driver.get(url)\n",
    "bs = BeautifulSoup(driver.page_source)\n",
    "\n",
    "page = etree.HTML(str(bs))\n",
    "\n",
    "\n",
    "infors = bs.find_all(\"div\", {\"class\": \"product-detail-top-left\"})[0]\n",
    "infors = infors.find_all(\"h1\")[0]\n",
    " \n",
    "print(infors.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install undetected_chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class crawling:\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.home_page = \"https://homedy.com/ban-nha-dat-ha-noi\"\n",
    "        self.root = \"https://homedy.com\"\n",
    "        self.page = 1\n",
    "\n",
    "    \n",
    "    def get_pages(self, page_source):\n",
    "        bs = BeautifulSoup(page_source)\n",
    "        page = etree.HTML(str(bs))\n",
    "\n",
    "        links = []\n",
    "        for i in page.xpath(\"\"\"//*[@id=\"MainPage\"]/div[3]/div[2]\"\"\")[0].getchildren():\n",
    "            try:\n",
    "                links.append(i.getchildren()[0][0].get(\"href\"))\n",
    "            except Exception as e:\n",
    "                print(e,  \"when get page\")\n",
    "        links = [link for link in links if link != None]\n",
    "        return [self.root+link for link in links]\n",
    "    \n",
    "    def next_page(self):\n",
    "        self.page += 1\n",
    "        return  self.home_page + \"f/p{self.page}\"\n",
    "\n",
    "    def get_id(self, page_source):\n",
    "        bs = BeautifulSoup(page_source)\n",
    "        page = etree.HTML(str(bs))\n",
    "        \n",
    "\n",
    "        infors = bs.find_all(\"div\", {\"class\": \"product-info\"})[0]\n",
    "        infor = infors.find_all(\"p\", {\"class\": \"code\"})\n",
    "        id = infor[-1].text\n",
    "        \n",
    "        \n",
    "        \n",
    "        return id\n",
    "    \n",
    "    def gather(self, page_source):\n",
    "        data = {}\n",
    "        bs = BeautifulSoup(page_source)\n",
    "        page = etree.HTML(str(bs))\n",
    "        \n",
    "        #get title  #done\n",
    "        infors = bs.find_all(\"div\", {\"class\": \"product-detail-top-left\"})[0]\n",
    "        infors = infors.find_all(\"h1\")[0]\n",
    "        \n",
    "        title = infors.text\n",
    "        data[\"Title\"] = title\n",
    "\n",
    "        #get price \n",
    "        infors = bs.find_all(\"div\", {\"class\": \"product-short-info\"})[0]\n",
    "        infors = infors.find_all(\"div\", {\"class\" :\"short-item\"})\n",
    "\n",
    "        price = infors[0].find_all(\"strong\")[0].text\n",
    "        data[\"Price\"] = price\n",
    "        #get area\n",
    "        area = infors[1].find_all(\"strong\")[0].text\n",
    "        data[\"Area\"] = area\n",
    "\n",
    "        #price = ''.join(page.xpath(\"\"\"/html/body/div[1]/div[5]/div[2]/div[2]/div/div[1]/div/div[1]/div/div[3]/div[1]/div[1]/strong\"\"\")[0].itertext())\n",
    "        #unit = page.xpath(\"\"\"/html/body/div[1]/div[5]/div[2]/div[2]/div/div[1]/div/div[1]/div/div[3]/div[1]/div[1]/strong\"\"\")[0].getchildren()[1].text\n",
    "        #data[\"Price\"] = price\n",
    "        #data[\"Unit\"] = unit\n",
    "\n",
    "        #get address #done\n",
    "        address =  page.xpath(\"\"\"/html/body/div[1]/div[5]/div[2]/div[2]/div/div[1]/div/div[1]/div/div[2]/a\"\"\")[0].get(\"title\")\n",
    "        address = [i.strip() for i in address.split(\",\")[::-1]]\n",
    "        data[\"Address\"] = address\n",
    "        \n",
    "\n",
    "        #get general description # done\n",
    "        descrip = ''.join(page.xpath(\"\"\"//*[@id=\"readmore\"]\"\"\")[0].itertext())\n",
    "        data[\"Gen_descrip\"] = descrip\n",
    "\n",
    "        #get product attributes\n",
    "        try:\n",
    "            list_items = page.xpath(\"\"\"/html/body/div[1]/div[5]/div[2]/div[2]/div/div[1]/div/div[3]\"\"\")[0].getchildren()\n",
    "            for item in list_items:\n",
    "                key, value = item.getchildren()\n",
    "                data[key.text] = value.text\n",
    "        except Exception as e:\n",
    "            print(e, \"no attributes\")\n",
    "        #get furniture  \n",
    "        try:\n",
    "            infors = bs.find_all(\"div\", {\"class\": \"utilities-detail furniture\"})[0]\n",
    "            infor = infors.find_all(\"div\", {\"class\": \"content\"})[0]\n",
    "            furs = infor.find_all(\"div\", {\"class\": \"title\"})\n",
    "            for fur in furs:\n",
    "                data[fur.text] = 1\n",
    "        except Exception as e:\n",
    "            print(e, \"has no furniture\")\n",
    "        # product informations\n",
    "        infors = bs.find_all(\"div\", {\"class\": \"product-info\"})[0]\n",
    "        infors = infors.find_all(\"div\")\n",
    "\n",
    "        for infor in infors:\n",
    "            label = infor.find_all(\"p\")[0]\n",
    "            code = infor.find_all(\"p\")[1]\n",
    "            data[label.text] =  code.text\n",
    "        return data\n",
    "    def run(self, start, num_of_pages):\n",
    "        service = webdriver.edge.service.Service(\"edgedriver_win64\\msedgedriver.exe\")\n",
    "        driver = webdriver.Edge(service=service)\n",
    "\n",
    "        \"\"\" options = webdriver.ChromeOptions() \n",
    "        options.add_argument(\"start-maximized\")\n",
    "        driver = uc.Chrome(options=options) \"\"\"\n",
    "\n",
    "        url = self.home_page\n",
    "        self.page = 1\n",
    "        if start != 1:\n",
    "            self.page = start\n",
    "            url = self.home_page+f\"/p{self.page}\"\n",
    "        if os.path.exists(\"data/index.json\"):\n",
    "            with open(\"data/index.json\") as f:\n",
    "                index = set(json.load(f))\n",
    "        else:\n",
    "            index = set()\n",
    "            \n",
    "        with open(\"log.txt\", \"w\") as f:\n",
    "            pass\n",
    "        \n",
    "        dataset = []\n",
    "        for i in range(num_of_pages):\n",
    "            num = 10\n",
    "            pages = []\n",
    "            while num > 0:\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    time.sleep(6)\n",
    "                    pages = self.get_pages(driver.page_source)\n",
    "                    driver.delete_all_cookies()\n",
    "                    break\n",
    "                except:\n",
    "                    num -= 1\n",
    "            if num <= 0:\n",
    "                url = self.next_page()\n",
    "                continue\n",
    "            #driver.close()\n",
    "            #service = webdriver.edge.service.Service(\"edgedriver_win64\\msedgedriver.exe\")\n",
    "            #driver = webdriver.Edge(service=service)\n",
    "            for page in tqdm(pages):\n",
    "                num = 1\n",
    "                \n",
    "\n",
    "                while num > 0:\n",
    "                    try:\n",
    "                        driver.get(page)\n",
    "                        time.sleep(6)\n",
    "\n",
    "                        id = self.get_id(driver.page_source)\n",
    "                        if id in index: \n",
    "                            print(id, \"exist\")\n",
    "                            break\n",
    "\n",
    "                        data = self.gather(driver.page_source)\n",
    "                        \n",
    "                        if data[\"ID tin\"] not in index:\n",
    "                            dataset.append(data)\n",
    "                            index.add(data[\"ID tin\"])\n",
    "                        with open(\"log.txt\", \"a\") as f:\n",
    "                            f.write(\"Success:\" + page +\"\\n\")\n",
    "                        driver.delete_all_cookies()\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(e, \"unknown\")\n",
    "                        with open(\"log.txt\", \"a\") as f:\n",
    "                            f.write(f\"Excution{5-num}: {page}\"+\"\\n\") \n",
    "                            f.write(traceback.format_exc()+\"\\n\")\n",
    "                        \n",
    "                        with open(\"failed.txt\", \"a\") as f:\n",
    "                            f.write(f\"Excution{5-num}: {page}\"+\"\\n\") \n",
    "                            f.write(traceback.format_exc()+\"\\n\")\n",
    "                        driver.delete_all_cookies()\n",
    "                        num -= 1\n",
    "            url = self.next_page()\n",
    "        if len(dataset) != 0:\n",
    "            df = pd.DataFrame(dataset)\n",
    "            df.to_csv(f\"data/{start}_{start+num_of_pages}_{time.time()}.csv\", index=False)\n",
    "        with open(\"data/index.json\", \"w\") as f:\n",
    "            json.dump(list(index), f)\n",
    "        driver.close()\n",
    "        \n",
    "craw = crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range when get page\n",
      "list index out of range when get page\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 7/18 [00:52<01:21,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range has no furniture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 8/18 [00:59<01:13,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range has no furniture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 12/18 [01:28<00:42,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range has no furniture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 15/18 [01:52<00:23,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range has no furniture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 16/18 [01:59<00:15,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list index out of range has no furniture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [02:13<00:00,  7.42s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TuanAnh\\OneDrive - Hanoi University of Science and Technology\\20221\\Introduction to DataScience\\crawling\\crawl_homedy.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m , \u001b[39m2\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     craw\u001b[39m.\u001b[39;49mrun(i, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     clear_output()\n",
      "\u001b[1;32mc:\\Users\\TuanAnh\\OneDrive - Hanoi University of Science and Technology\\20221\\Introduction to DataScience\\crawling\\crawl_homedy.ipynb Cell 7\u001b[0m in \u001b[0;36mcrawling.run\u001b[1;34m(self, start, num_of_pages)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dataset) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(dataset)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m     df\u001b[39m.\u001b[39;49mto_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/\u001b[39;49m\u001b[39m{\u001b[39;49;00mstart\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mstart\u001b[39m+\u001b[39;49mnum_of_pages\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mtime\u001b[39m.\u001b[39;49mtime()\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mdata/index.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TuanAnh/OneDrive%20-%20Hanoi%20University%20of%20Science%20and%20Technology/20221/Introduction%20to%20DataScience/crawling/crawl_homedy.ipynb#W6sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m     json\u001b[39m.\u001b[39mdump(\u001b[39mlist\u001b[39m(index), f)\n",
      "File \u001b[1;32mc:\\Users\\TuanAnh\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3549\u001b[0m )\n\u001b[1;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3552\u001b[0m     path_or_buf,\n\u001b[0;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[0;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3568\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\TuanAnh\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1179\u001b[0m )\n\u001b[1;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\TuanAnh\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\TuanAnh\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:697\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[1;32m--> 697\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[0;32m    699\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    701\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TuanAnh\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:571\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    569\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[0;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[1;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "for i in range(1 , 2):\n",
    "    craw.run(i, 1)\n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
